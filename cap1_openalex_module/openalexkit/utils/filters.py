"""
ë…¼ë¬¸ í•„í„°ë§ ë° ì¬ë­í‚¹ ìœ í‹¸ë¦¬í‹°
"""
import re
import logging
from typing import List, Dict

logger = logging.getLogger(__name__)


def deduplicate_papers(papers: List[Dict]) -> List[Dict]:
    """
    ì¤‘ë³µ ë…¼ë¬¸ ì œê±° (DOI or ì •ê·œí™”ëœ ì œëª©)
    
    ìš°ì„ ìˆœìœ„:
    1. DOI ì¡´ì¬ â†’ DOIë¡œ ì¤‘ë³µ ì²´í¬
    2. DOI ì—†ìŒ â†’ ì •ê·œí™”ëœ ì œëª©ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
    
    Args:
        papers: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ì¤‘ë³µ ì œê±°ëœ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
    """
    seen = set()
    unique = []
    
    for paper in papers:
        # DOI ìš°ì„ , ì—†ìœ¼ë©´ ì •ê·œí™”ëœ ì œëª©
        url = paper.get("url", "")
        
        # DOIê°€ ìˆìœ¼ë©´ DOIë¡œ ì¤‘ë³µ ì²´í¬
        if url and url.startswith("http"):
            key = url
        else:
            # DOI ì—†ìœ¼ë©´ ì œëª©ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
            key = _normalize_title(paper.get("title", ""))
        
        if key and key not in seen:
            seen.add(key)
            unique.append(paper)
    
    logger.info(f"ğŸ” ì¤‘ë³µ ì œê±°: {len(papers)}ê°œ â†’ {len(unique)}ê°œ")
    return unique


def rerank_papers(papers: List[Dict], query: Dict) -> List[Dict]:
    """
    ê°„ë‹¨í•œ ì¬ë­í‚¹ (í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜)
    
    ì ìˆ˜ ê³„ì‚°:
    - match_score = ì œëª© ë§¤ì¹­ * 3 + ì´ˆë¡ ë§¤ì¹­ * 1
    
    ì •ë ¬:
    - (match_score, relevance_score) ë‚´ë¦¼ì°¨ìˆœ
    
    Args:
        papers: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (tokens í¬í•¨)
        
    Returns:
        ì¬ë­í‚¹ëœ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
    """
    tokens = [kw.lower() for kw in query.get("tokens", [])]
    
    for paper in papers:
        title_lower = paper.get("title", "").lower()
        abstract_lower = paper.get("abstract", "").lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
        match_score = 0
        for kw in tokens:
            if kw in title_lower:
                match_score += 3
            if kw in abstract_lower:
                match_score += 1
        
        paper["match_score"] = match_score
    
    # ë§¤ì¹­ ì ìˆ˜ + relevance_score ê¸°ì¤€ ì •ë ¬
    papers.sort(
        key=lambda x: (x.get("match_score", 0), x.get("relevance_score", 0)), 
        reverse=True
    )
    
    logger.info(f"ğŸ”„ ì¬ë­í‚¹ ì™„ë£Œ: ìƒìœ„ ë…¼ë¬¸ match_score={papers[0].get('match_score', 0) if papers else 0}")
    
    return papers


def _normalize_title(title: str) -> str:
    """
    ì œëª© ì •ê·œí™” (ì†Œë¬¸ì + íŠ¹ìˆ˜ë¬¸ì ì œê±°)
    
    Args:
        title: ë…¼ë¬¸ ì œëª©
        
    Returns:
        ì •ê·œí™”ëœ ì œëª©
    """
    return re.sub(r'[^\w\s]', '', title.lower()).strip()
