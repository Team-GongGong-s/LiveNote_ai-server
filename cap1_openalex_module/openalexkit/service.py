"""
OpenAlexKit í•µì‹¬ ì„œë¹„ìŠ¤
"""
import asyncio
import logging
from typing import List

from .models import OpenAlexRequest, OpenAlexResponse, PaperInfo
from .config.openalex_config import OpenAlexConfig
from .config import flags
from .api.openalex_client import OpenAlexAPIClient
from .llm.openai_client import OpenAIClient
from .utils.filters import deduplicate_papers, rerank_papers

logger = logging.getLogger(__name__)


class OpenAlexService:
    """OpenAlex ë…¼ë¬¸ ì¶”ì²œ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        # ì„¤ì • ê²€ì¦
        OpenAlexConfig.validate()
        
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.api_client = OpenAlexAPIClient()
        self.llm_client = OpenAIClient()
    
    async def recommend_papers(
        self, 
        request: OpenAlexRequest
    ) -> List[OpenAlexResponse]:
        """
        ë…¼ë¬¸ ì¶”ì²œ (ë³‘ë ¬ ê²€ì¦)
        
        íë¦„:
        1. ì„¹ì…˜ ìš”ì•½ â†’ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (LLM)
        2. OpenAlex API í˜¸ì¶œ (í•„í„° ì ìš©)
        3. ë…¼ë¬¸ íŒŒì‹± + ì¤‘ë³µ ì œê±° + ìž¬ëž­í‚¹
        4. ìƒìœ„ Nê°œ ì„ íƒ (CARD_LIMIT)
        5. ì¡°ê±´ë¶€ ê²€ì¦:
           - verify_openalex=True: LLM ë³‘ë ¬ ê²€ì¦
           - verify_openalex=False: Heuristic ìŠ¤ì½”ì–´ë§
        6. ì ìˆ˜ ìˆœ ì •ë ¬ â†’ top_k ë°˜í™˜
        
        Args:
            request: OpenAlexRequest
        
        Returns:
            List[OpenAlexResponse]: ì¶”ì²œ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ (top_kê°œ)
        """
        logger.info(
            f"ðŸš€ ë…¼ë¬¸ ì¶”ì²œ ì‹œìž‘: lecture={request.lecture_id}, "
            f"section={request.section_id}, verify={request.verify_openalex}"
        )
        
        try:
            # 1. ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (LLM)
            query = await self._generate_search_query(request)
            
            if not query.get("tokens"):
                logger.warning("âš ï¸  ê²€ìƒ‰ í† í°ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return []
            
            # 2. OpenAlex API í˜¸ì¶œ
            papers = await self.api_client.search_papers(
                query=query,
                exclude_ids=request.exclude_ids,
                sort_by=request.sort_by
            )
            
            if not papers:
                logger.warning("âš ï¸  ê²€ìƒ‰ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # 3. ì¤‘ë³µ ì œê±° + ìž¬ëž­í‚¹
            papers = deduplicate_papers(papers)
            papers = rerank_papers(papers, query)
            
            # 4. ìƒìœ„ Nê°œ ì„ íƒ (CARD_LIMIT)
            papers = papers[:OpenAlexConfig.CARD_LIMIT]
            logger.info(f"ðŸ“„ ê²€ì¦ ëŒ€ìƒ: {len(papers)}ê°œ (ìƒí•œ: {OpenAlexConfig.CARD_LIMIT})")
            
            # ðŸš€ NO_SCORING ëª¨ë“œ: ê²€ì¦ ì—†ì´ ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜
            if flags.NO_SCORING:
                logger.info("âš¡ NO_SCORING ëª¨ë“œ: ê²€ì¦ ìŠ¤í‚µ")
                results = []
                for paper in papers[:request.top_k]:
                    info = PaperInfo(
                        title=paper.get("title", "Unknown"),
                        authors=paper.get("authors", []),
                        year=paper.get("publication_year"),
                        citations=paper.get("cited_by_count", 0),
                        url=paper.get("url", ""),
                        abstract=paper.get("abstract", "No abstract available")[:500]
                    )
                    results.append(OpenAlexResponse(
                        lecture_id=request.lecture_id,
                        section_id=request.section_id,
                        paper_info=info,
                        reason="search",
                        score=10.0
                    ))
                logger.info(f"âœ… NO_SCORING ê²°ê³¼: {len(results)}ê°œ ë°˜í™˜")
                return results
            
            # 5. ì¡°ê±´ë¶€ ê²€ì¦
            if request.verify_openalex:
                # LLM ë³‘ë ¬ ê²€ì¦
                results = await self._verify_papers_parallel(papers, request, query)
            else:
                # Heuristic ìŠ¤ì½”ì–´ë§
                results = self._heuristic_score(papers, query, request)
            
            # 6. ì ìˆ˜ í•„í„°ë§ (min_score ì´ìƒë§Œ ì„ íƒ)
            filtered_results = [r for r in results if r.score >= request.min_score]
            
            if len(filtered_results) < len(results):
                logger.info(
                    f"ðŸ” ì ìˆ˜ í•„í„°ë§: {len(results)}ê°œ â†’ {len(filtered_results)}ê°œ "
                    f"(min_score: {request.min_score})"
                )
            
            # 7. ì ìˆ˜ ìˆœ ì •ë ¬ + top_k ë°˜í™˜ (í•„í„°ë§ëœ ê²°ê³¼ì—ì„œ)
            filtered_results.sort(key=lambda x: x.score, reverse=True)
            final_results = filtered_results[:request.top_k]
            
            if final_results:
                logger.info(
                    f"âœ… ë…¼ë¬¸ ì¶”ì²œ ì™„ë£Œ: {len(final_results)}ê°œ "
                    f"(ìµœê³  ì ìˆ˜: {final_results[0].score:.1f})"
                )
            else:
                logger.warning(f"âš ï¸  min_score {request.min_score} ì´ìƒì¸ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤")
            
            return final_results
            
        except Exception as e:
            logger.error(f"âŒ ë…¼ë¬¸ ì¶”ì²œ ì‹¤íŒ¨: {e}")
            return []
    
    async def _generate_search_query(self, request: OpenAlexRequest) -> dict:
        """
        ì„¹ì…˜ ìš”ì•½ â†’ OpenAlex ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (LLM)
        
        Args:
            request: OpenAlexRequest
            
        Returns:
            {"tokens": ["term1", "term2"], "year_from": 2015}
        """
        try:
            # LLMì—ê²Œ ì „ë‹¬í•  ë°ì´í„° ì¤€ë¹„
            request_data = {
                "section_summary": request.section_summary,
                "previous_summaries": request.previous_summaries,
                "rag_context": request.rag_context,
            }
            
            # LLM ì¿¼ë¦¬ ìƒì„±
            result = await self.llm_client.generate_query(request_data)
            
            # year_from ì¶”ê°€
            result["year_from"] = request.year_from
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"tokens": [], "year_from": request.year_from}
    
    async def _verify_papers_parallel(
        self, 
        papers: List[dict], 
        request: OpenAlexRequest,
        query: dict
    ) -> List[OpenAlexResponse]:
        """
        ë³‘ë ¬ LLM ê²€ì¦ (Semaphore ë™ì‹œì„± ì œì–´)
        
        Args:
            papers: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
            request: OpenAlexRequest
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (tokens í¬í•¨)
            
        Returns:
            List[OpenAlexResponse]: ê²€ì¦ëœ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        semaphore = asyncio.Semaphore(OpenAlexConfig.VERIFY_CONCURRENCY)
        
        async def verify_with_limit(paper: dict):
            async with semaphore:
                return await self._verify_single_paper(paper, request, query)
        
        logger.info(f"âœ¨ ë³‘ë ¬ LLM ê²€ì¦ ì‹œìž‘ (ë™ì‹œì„±: {OpenAlexConfig.VERIFY_CONCURRENCY})")
        
        results = await asyncio.gather(
            *[verify_with_limit(paper) for paper in papers],
            return_exceptions=True
        )
        
        # ì—ëŸ¬ ì²˜ë¦¬
        verified = []
        for paper, result in zip(papers, results):
            if isinstance(result, Exception):
                logger.error(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {result}")
                # Fallback: score=5.0
                verified.append(OpenAlexResponse(
                    lecture_id=request.lecture_id,
                    section_id=request.section_id,
                    paper_info=self._parse_paper_info(paper),
                    reason="ê²€ì¦ ì‹¤íŒ¨ (fallback)",
                    score=5.0
                ))
            else:
                verified.append(result)
        
        logger.info(f"âœ… ë³‘ë ¬ ê²€ì¦ ì™„ë£Œ: {len(verified)}ê°œ")
        
        return verified
    
    async def _verify_single_paper(
        self, 
        paper: dict, 
        request: OpenAlexRequest,
        query: dict
    ) -> OpenAlexResponse:
        """
        ë‹¨ì¼ ë…¼ë¬¸ ê²€ì¦ (LLM)
        
        Args:
            paper: ë…¼ë¬¸ ì •ë³´
            request: OpenAlexRequest
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (tokens í¬í•¨)
            
        Returns:
            OpenAlexResponse
        """
        try:
            # í‚¤ì›Œë“œ ë¬¸ìžì—´ ìƒì„±
            keywords = ", ".join(query.get("tokens", []))
            
            # LLM ê²€ì¦
            result = await self.llm_client.score_paper(
                paper=paper,
                section_summary=request.section_summary,
                keywords=keywords
            )
            
            return OpenAlexResponse(
                lecture_id=request.lecture_id,
                section_id=request.section_id,
                paper_info=self._parse_paper_info(paper),
                reason=result.get("reason", "ê²€ì¦ ì™„ë£Œ"),
                score=result.get("score", 5.0)
            )
            
        except Exception as e:
            logger.error(f"âŒ ë…¼ë¬¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return OpenAlexResponse(
                lecture_id=request.lecture_id,
                section_id=request.section_id,
                paper_info=self._parse_paper_info(paper),
                reason="ê²€ì¦ ì‹¤íŒ¨ (ì˜¤ë¥˜)",
                score=5.0
            )
    
    def _heuristic_score(
        self, 
        papers: List[dict], 
        query: dict,
        request: OpenAlexRequest
    ) -> List[OpenAlexResponse]:
        """
        Heuristic ìŠ¤ì½”ì–´ë§ (LLM ì—†ì´ ë¹ ë¥¸ í‰ê°€)
        
        ì ìˆ˜ ê³„ì‚°:
        - ì œëª© í‚¤ì›Œë“œ ë§¤ì¹­: +3ì 
        - ì´ˆë¡ í‚¤ì›Œë“œ ë§¤ì¹­: +1ì 
        - relevance_score ê°€ì¤‘ì¹˜: +2ì 
        - ê¸°ë³¸ ì ìˆ˜: 5.0
        
        Args:
            papers: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (tokens í¬í•¨)
            request: OpenAlexRequest
            
        Returns:
            List[OpenAlexResponse]: ì ìˆ˜ê°€ ë¶€ì—¬ëœ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("ðŸ”¢ Heuristic ìŠ¤ì½”ì–´ë§ ì‹œìž‘...")
        
        tokens = [kw.lower() for kw in query.get("tokens", [])]
        results = []
        
        for paper in papers:
            title_lower = paper.get("title", "").lower()
            abstract_lower = paper.get("abstract", "").lower()
            
            # ê¸°ë³¸ ì ìˆ˜
            score = 5.0
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            for kw in tokens:
                if kw in title_lower:
                    score += 0.5
                if kw in abstract_lower:
                    score += 0.2
            
            # relevance_score ê°€ì¤‘ì¹˜
            relevance = paper.get("relevance_score", 0)
            score += min(relevance / 10, 2.0)  # ìµœëŒ€ +2ì 
            
            # 10ì  ì´ˆê³¼ ë°©ì§€
            score = min(score, 10.0)
            
            # ì´ìœ  ìƒì„± (ë‹¨ìˆœí™”)
            reason = "Heuristic"
            
            results.append(OpenAlexResponse(
                lecture_id=request.lecture_id,
                section_id=request.section_id,
                paper_info=self._parse_paper_info(paper),
                reason=reason,
                score=score
            ))
        
        logger.info(f"âœ… Heuristic ìŠ¤ì½”ì–´ë§ ì™„ë£Œ: {len(results)}ê°œ")
        
        return results
    
    def _parse_paper_info(self, paper: dict) -> PaperInfo:
        """
        ë…¼ë¬¸ ì •ë³´ë¥¼ PaperInfoë¡œ ë³€í™˜
        
        Args:
            paper: ë…¼ë¬¸ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            PaperInfo
        """
        return PaperInfo(
            url=paper.get("url", ""),
            title=paper.get("title", ""),
            abstract=paper.get("abstract", "")[:OpenAlexConfig.ABSTRACT_MAX_LENGTH],
            year=paper.get("year"),
            cited_by_count=paper.get("cited_by_count", 0),
            authors=paper.get("authors", [])
        )
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        await self.api_client.close()
