"""
OpenAlexKit í†µí•© í…ŒìŠ¤íŠ¸ (íŒŒë¼ë¯¸í„° ë³€í˜• í…ŒìŠ¤íŠ¸)
- ì…ë ¥ íŒŒë¼ë¯¸í„° ëª…í™•íˆ í‘œì‹œ
- ì¶œë ¥ ê²°ê³¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
- ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„° ì¡°í•© í…ŒìŠ¤íŠ¸
  * top_k ë³€í˜•: 1, 3, 5, 10 (4ê°œ)
  * sort_by ë³€í˜•: relevance, cited_by_count, hybrid (4ê°œ)
  * min_score ë³€í˜•: 1.0, 3.0, 5.0, 7.0 (4ê°œ)
  * hybrid+LLM+context: ì „ì²´ ì»¨í…ìŠ¤íŠ¸ í™œìš© (2ê°œ)
- ì´ 14ê°œ ì‹œë‚˜ë¦¬ì˜¤
"""
import asyncio
import logging
import os
import sys
from typing import List
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from openalexkit import (
    OpenAlexService,
    OpenAlexRequest,
    PreviousSectionSummary,
    RAGChunk
)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë¡œê¹… ì„¤ì •
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
logging.basicConfig(
    level=logging.WARNING,  # í…ŒìŠ¤íŠ¸ ì¶œë ¥ ê¹”ë”í•˜ê²Œ
    format='%(message)s'
)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜ (14ê°œ - 4ê°€ì§€ íŒŒë¼ë¯¸í„° ë³€í˜•)
# - top_k ë³€í˜•: 4ê°œ ì‹œë‚˜ë¦¬ì˜¤ (top_k=1, 3, 5, 10)
# - sort_by ë³€í˜•: 4ê°œ ì‹œë‚˜ë¦¬ì˜¤ (relevance, cited_by_count, hybrid x2)
# - min_score ë³€í˜•: 4ê°œ ì‹œë‚˜ë¦¬ì˜¤ (1.0, 3.0, 5.0, 7.0)
# - hybrid+LLM+context: 2ê°œ ì‹œë‚˜ë¦¬ì˜¤ (ì „ì²´ ì»¨í…ìŠ¤íŠ¸ í™œìš©)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TEST_SCENARIOS = [
    # â”â”â” Group 1: top_k ë³€í˜• (4ê°œ) â”â”â”
    {
        "name": "1ï¸âƒ£ [top_k=1] CS - ì•Œê³ ë¦¬ì¦˜ (ë‹¨ì¼ ë…¼ë¬¸ ì¶”ì²œ)",
        "request": OpenAlexRequest(
            lecture_id="topk_test_1",
            section_id=1,
            section_summary="í€µì†ŒíŠ¸ ì•Œê³ ë¦¬ì¦˜ì˜ ì‹œê°„ ë³µì¡ë„ì™€ ë¶„í•  ì •ë³µ ì „ëµ",
            language="ko",
            top_k=1,  # 1ê°œë§Œ
            verify_openalex=True,
            year_from=2000,
            sort_by="hybrid"
        )
    },
    {
        "name": "2ï¸âƒ£ [top_k=3] Physics - ì–‘ìì—­í•™ (3ê°œ ì¶”ì²œ)",
        "request": OpenAlexRequest(
            lecture_id="topk_test_3",
            section_id=1,
            section_summary="SchrÃ¶dinger equation and quantum superposition",
            language="en",
            top_k=3,  # 3ê°œ
            verify_openalex=True,
            year_from=2005,
            sort_by="hybrid"
        )
    },
    {
        "name": "3ï¸âƒ£ [top_k=5] ML - Transformer (5ê°œ ì¶”ì²œ)",
        "request": OpenAlexRequest(
            lecture_id="topk_test_5",
            section_id=1,
            section_summary="Attention mechanism in Transformer architecture",
            language="en",
            top_k=5,  # 5ê°œ (ê¸°ë³¸ê°’)
            verify_openalex=False,  # Heuristic (ë¹ ë¦„)
            year_from=2017,
            sort_by="hybrid"
        )
    },
    {
        "name": "4ï¸âƒ£ [top_k=10] Math - ì„ í˜•ëŒ€ìˆ˜ (10ê°œ ì¶”ì²œ)",
        "request": OpenAlexRequest(
            lecture_id="topk_test_10",
            section_id=1,
            section_summary="ê³ ìœ ê°’ê³¼ ê³ ìœ ë²¡í„°ì˜ ì‘ìš©: PCAì™€ ê·¸ë˜í”„ ì´ë¡ ",
            language="ko",
            top_k=10,  # 10ê°œ (ìµœëŒ€)
            verify_openalex=False,
            year_from=2010,
            sort_by="hybrid"
        )
    },
    
    # â”â”â” Group 2: sort_by ë³€í˜• (4ê°œ) â”â”â”
    {
        "name": "5ï¸âƒ£ [relevance] Chemistry - ìœ ê¸°í™”í•™ (ì—°ê´€ì„± ìš°ì„ )",
        "request": OpenAlexRequest(
            lecture_id="sort_relevance",
            section_id=1,
            section_summary="ë²¤ì   ê³ ë¦¬ì˜ ê³µëª… êµ¬ì¡°ì™€ ë°©í–¥ì¡±ì„±",
            language="ko",
            top_k=3,
            verify_openalex=False,
            year_from=2005,
            sort_by="relevance"  # ì—°ê´€ì„± ìš°ì„ 
        )
    },
    {
        "name": "6ï¸âƒ£ [cited_by_count] Biology - ì„¸í¬ìƒë¬¼í•™ (ì¸ìš©ìˆ˜ ìš°ì„ )",
        "request": OpenAlexRequest(
            lecture_id="sort_citation",
            section_id=1,
            section_summary="ë¯¸í† ì½˜ë“œë¦¬ì•„ì˜ ATP ìƒì„±ê³¼ ì „ìì „ë‹¬ê³„",
            language="ko",
            top_k=3,
            verify_openalex=True,
            year_from=2010,
            sort_by="cited_by_count"  # ì¸ìš©ìˆ˜ ìš°ì„ 
        )
    },
    {
        "name": "7ï¸âƒ£ [hybrid] Economics - ê²Œì„ì´ë¡  (ê· í˜• ì •ë ¬)",
        "request": OpenAlexRequest(
            lecture_id="sort_hybrid_1",
            section_id=1,
            section_summary="Nash equilibrium and prisoner's dilemma",
            language="en",
            top_k=3,
            verify_openalex=False,
            year_from=1990,
            sort_by="hybrid"  # ê· í˜•
        )
    },
    {
        "name": "8ï¸âƒ£ [hybrid] CS - ë°ì´í„°ë² ì´ìŠ¤ (ê· í˜• ì •ë ¬)",
        "request": OpenAlexRequest(
            lecture_id="sort_hybrid_2",
            section_id=1,
            section_summary="B-Tree index structure and range query optimization",
            language="en",
            top_k=3,
            verify_openalex=True,
            year_from=2015,
            sort_by="hybrid"  # ê· í˜•
        )
    },
    
    # â”â”â” Group 3: min_score ë³€í˜• (4ê°œ) â”â”â”
    {
        "name": "9ï¸âƒ£ [min_score=1.0] Psychology - ì¸ì§€ì‹¬ë¦¬í•™ (ë‚®ì€ ì„ê³„ê°’)",
        "request": OpenAlexRequest(
            lecture_id="minscore_1",
            section_id=1,
            section_summary="ì‘ì—… ê¸°ì–µê³¼ ì£¼ì˜ ì§‘ì¤‘ì˜ ì‹ ê²½ê³¼í•™ì  ë©”ì»¤ë‹ˆì¦˜",
            language="ko",
            top_k=5,
            verify_openalex=False,
            year_from=2010,
            sort_by="hybrid",
            min_score=1.0  # ë§¤ìš° ë‚®ì€ ì„ê³„ê°’ (ê±°ì˜ ëª¨ë‘ í†µê³¼)
        )
    },
    {
        "name": "ğŸ”Ÿ [min_score=3.0] History - ê·¼ëŒ€ì‚¬ (ê¸°ë³¸ ì„ê³„ê°’)",
        "request": OpenAlexRequest(
            lecture_id="minscore_3",
            section_id=1,
            section_summary="ì‚°ì—…í˜ëª…ì´ ìœ ëŸ½ ì‚¬íšŒì— ë¯¸ì¹œ ì˜í–¥",
            language="ko",
            top_k=5,
            verify_openalex=False,
            year_from=2000,
            sort_by="hybrid",
            min_score=3.0  # ê¸°ë³¸ê°’
        )
    },
    {
        "name": "1ï¸âƒ£1ï¸âƒ£ [min_score=5.0] Physics - ìƒëŒ€ì„±ì´ë¡  (ì¤‘ê°„ ì„ê³„ê°’)",
        "request": OpenAlexRequest(
            lecture_id="minscore_5",
            section_id=1,
            section_summary="Special relativity: time dilation and length contraction",
            language="en",
            top_k=5,
            verify_openalex=True,
            year_from=2000,
            sort_by="hybrid",
            min_score=5.0  # ì¤‘ê°„ ì„ê³„ê°’ (í’ˆì§ˆ ì¤‘ì‹œ)
        )
    },
    {
        "name": "1ï¸âƒ£2ï¸âƒ£ [min_score=7.0] AI - ë”¥ëŸ¬ë‹ (ë†’ì€ ì„ê³„ê°’)",
        "request": OpenAlexRequest(
            lecture_id="minscore_7",
            section_id=1,
            section_summary="Convolutional neural networks for image recognition",
            language="en",
            top_k=5,
            verify_openalex=True,
            year_from=2012,
            sort_by="hybrid",
            min_score=7.0  # ë†’ì€ ì„ê³„ê°’ (ë§¤ìš° ì—„ê²©, ì¼ë¶€ë§Œ í†µê³¼)
        )
    },
    
    # â”â”â” Group 4: hybrid + LLM + full context (2ê°œ) â”â”â”
    {
        "name": "1ï¸âƒ£3ï¸âƒ£ [hybrid+LLM+context] ML - ê°•í™”í•™ìŠµ (ì „ì²´ ì»¨í…ìŠ¤íŠ¸)",
        "request": OpenAlexRequest(
            lecture_id="hybrid_llm_1",
            section_id=3,
            section_summary="Q-learningê³¼ DQNì˜ ì°¨ì´: Experience Replayì™€ Target Networkì˜ ì—­í• ",
            language="ko",
            top_k=5,
            verify_openalex=True,  # LLM ê²€ì¦
            previous_summaries=[
                PreviousSectionSummary(
                    section_id=1,
                    summary="ê°•í™”í•™ìŠµì˜ ê¸°ë³¸ ê°œë…: ì—ì´ì „íŠ¸, í™˜ê²½, ìƒíƒœ, í–‰ë™, ë³´ìƒ"
                ),
                PreviousSectionSummary(
                    section_id=2,
                    summary="Markov Decision Processì™€ Bellman ë°©ì •ì‹"
                )
            ],
            rag_context=[
                RAGChunk(
                    text="3ì¥. Deep Q-Network (DQN)\n- Experience Replay: í•™ìŠµ ë°ì´í„°ì˜ ìƒê´€ê´€ê³„ ì œê±°\n- Target Network: í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ",
                    score=0.94
                ),
                RAGChunk(
                    text="Q-learningì€ í…Œì´ë¸” ê¸°ë°˜ ë°©ë²•ì´ê³ , DQNì€ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ Q-functionì„ ê·¼ì‚¬í•©ë‹ˆë‹¤.",
                    score=0.88
                )
            ],
            year_from=2013,
            sort_by="hybrid",
            min_score=5.0
        )
    },
    {
        "name": "1ï¸âƒ£4ï¸âƒ£ [hybrid+LLM+context] NLP - Transformer (ì „ì²´ ì»¨í…ìŠ¤íŠ¸)",
        "request": OpenAlexRequest(
            lecture_id="hybrid_llm_2",
            section_id=4,
            section_summary="BERTì™€ GPTì˜ ì°¨ì´ì : Bidirectional vs Autoregressive ì‚¬ì „í•™ìŠµ",
            language="ko",
            top_k=5,
            verify_openalex=True,  # LLM ê²€ì¦
            previous_summaries=[
                PreviousSectionSummary(
                    section_id=1,
                    summary="ìì—°ì–´ì²˜ë¦¬ì˜ ë°œì „: RNN â†’ LSTM â†’ Attention Mechanism"
                ),
                PreviousSectionSummary(
                    section_id=2,
                    summary="Transformer ì•„í‚¤í…ì²˜: Self-Attentionê³¼ Positional Encoding"
                ),
                PreviousSectionSummary(
                    section_id=3,
                    summary="ì „ì´í•™ìŠµ(Transfer Learning)ê³¼ ì‚¬ì „í•™ìŠµ(Pre-training)ì˜ ì¤‘ìš”ì„±"
                )
            ],
            rag_context=[
                RAGChunk(
                    text="BERT (Bidirectional Encoder Representations from Transformers)\n- Masked Language Model (MLM) ì‚¬ì „í•™ìŠµ\n- ì–‘ë°©í–¥ ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ\n- ë¶„ë¥˜, NER ë“± í•˜ë¥˜ íƒœìŠ¤í¬ì— íš¨ê³¼ì ",
                    score=0.96
                ),
                RAGChunk(
                    text="GPT (Generative Pre-trained Transformer)\n- Causal Language Model (CLM) ì‚¬ì „í•™ìŠµ\n- ë‹¨ë°©í–¥(ì™¼ìª½â†’ì˜¤ë¥¸ìª½) ì»¨í…ìŠ¤íŠ¸\n- í…ìŠ¤íŠ¸ ìƒì„±ì— íŠ¹í™”",
                    score=0.91
                ),
                RAGChunk(
                    text="ì‚¬ì „í•™ìŠµ ëª¨ë¸ì€ ëŒ€ê·œëª¨ ì½”í¼ìŠ¤ì—ì„œ ì–¸ì–´ì˜ íŒ¨í„´ì„ í•™ìŠµí•œ í›„, ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¯¸ì„¸ì¡°ì •(Fine-tuning)í•©ë‹ˆë‹¤.",
                    score=0.85
                )
            ],
            year_from=2017,
            sort_by="hybrid",
            min_score=6.0
        )
    }
]


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def print_separator(char="â”", length=80):
    """êµ¬ë¶„ì„  ì¶œë ¥"""
    print(char * length)


def print_header(text: str):
    """í—¤ë” ì¶œë ¥"""
    print_separator()
    print(f"ğŸ“Œ {text}")
    print_separator()


def print_input_params(request: OpenAlexRequest):
    """ì…ë ¥ íŒŒë¼ë¯¸í„° ì¶œë ¥"""
    print("\nğŸ”¹ ì…ë ¥ íŒŒë¼ë¯¸í„°:")
    print(f"   Lecture ID: {request.lecture_id}")
    print(f"   Section ID: {request.section_id}")
    print(f"   Section Summary: {request.section_summary}")
    
    if request.previous_summaries:
        print(f"   Previous Summaries: {len(request.previous_summaries)}ê°œ")
        for ps in request.previous_summaries:
            print(f"      - ì„¹ì…˜ {ps.section_id}: {ps.summary}")
    else:
        print(f"   Previous Summaries: (ì—†ìŒ)")
    
    if request.rag_context:
        print(f"   RAG Context: {len(request.rag_context)}ê°œ")
        for rc in request.rag_context:
            print(f"      - [{rc.score:.2f}] {rc.text}")
    else:
        print(f"   RAG Context: (ì—†ìŒ)")
    
    print(f"   Language: {request.language}")
    print(f"   Top K: {request.top_k}")
    print(f"   Verify OpenAlex: {'LLM' if request.verify_openalex else 'Heuristic'}")
    print(f"   Year From: {request.year_from}")
    print(f"   Sort By: {request.sort_by}")
    print(f"   Min Score: {request.min_score}")
    
    if request.exclude_ids:
        print(f"   Exclude IDs: {request.exclude_ids}")


def print_paper_result(idx: int, paper):
    """ë…¼ë¬¸ ê²°ê³¼ ì¶œë ¥ (ë³´ê¸° ì¢‹ê²Œ)"""
    print(f"\n   [{idx}] ì ìˆ˜: {paper.score:.1f}/10")
    print(f"       ì œëª©: {paper.paper_info.title}")
    
    # ì €ì (ìµœëŒ€ 3ëª…)
    authors = paper.paper_info.authors[:3] if paper.paper_info.authors else []
    authors_str = ", ".join(authors)
    if len(paper.paper_info.authors) > 3:
        authors_str += f" ì™¸ {len(paper.paper_info.authors) - 3}ëª…"
    print(f"       ì €ì: {authors_str if authors_str else 'N/A'}")
    
    print(f"       ì¶œíŒì—°ë„: {paper.paper_info.year}")
    print(f"       ì¸ìš©íšŸìˆ˜: {paper.paper_info.cited_by_count}")
    print(f"       ì´ˆë¡: {paper.paper_info.abstract}")
    print(f"       URL: {paper.paper_info.url}")
    print(f"       í‰ê°€: {paper.reason}")


async def run_single_test(scenario: dict, service: OpenAlexService) -> dict:
    """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    name = scenario["name"]
    request = scenario["request"]
    
    print_header(name)
    print_input_params(request)
    
    print("\nğŸ”¹ ì‹¤í–‰ ì¤‘...")
    import time
    start = time.time()
    
    try:
        results = await service.recommend_papers(request)
        elapsed = time.time() - start
        
        print(f"\nâœ… ì™„ë£Œ! (ì‹¤í–‰ì‹œê°„: {elapsed:.2f}ì´ˆ)")
        print(f"\nğŸ”¹ ì¶œë ¥ ê²°ê³¼: {len(results)}ê°œ ë…¼ë¬¸")
        
        if results:
            for idx, paper in enumerate(results, 1):
                print_paper_result(idx, paper)
        else:
            print("   (ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)")
        
        return {
            "name": name,
            "status": "ì„±ê³µ",
            "count": len(results),
            "elapsed": elapsed
        }
    
    except Exception as e:
        elapsed = time.time() - start
        print(f"\nâŒ ì‹¤íŒ¨: {e}")
        return {
            "name": name,
            "status": "ì‹¤íŒ¨",
            "error": str(e),
            "elapsed": elapsed
        }


async def run_all_tests():
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    # API í‚¤ í™•ì¸
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY", "")
    
    print_header("OpenAlexKit í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"âœ… API í‚¤ ë¡œë“œ ì™„ë£Œ: {api_key[:20]}...")
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: {len(TEST_SCENARIOS)}ê°œ\n")
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = OpenAlexService()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = []
    for idx, scenario in enumerate(TEST_SCENARIOS, 1):
        print(f"\n{'='*80}")
        print(f"í…ŒìŠ¤íŠ¸ {idx}/{len(TEST_SCENARIOS)}")
        result = await run_single_test(scenario, service)
        results.append(result)
        await asyncio.sleep(0.5)  # API Rate Limit ë°©ì§€
    
    # ì„œë¹„ìŠ¤ ì¢…ë£Œ
    await service.close()
    
    # ìš”ì•½ ì¶œë ¥
    print_header("í…ŒìŠ¤íŠ¸ ìš”ì•½")
    total_time = sum(r["elapsed"] for r in results)
    success_count = sum(1 for r in results if r["status"] == "ì„±ê³µ")
    
    print(f"âœ… ì„±ê³µ: {success_count}/{len(results)}")
    print(f"â±ï¸  ì´ ì‹¤í–‰ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"\nìƒì„¸ ê²°ê³¼:")
    
    for r in results:
        status_icon = "âœ…" if r["status"] == "ì„±ê³µ" else "âŒ"
        if r["status"] == "ì„±ê³µ":
            print(f"  {status_icon} {r['name']}: {r['count']}ê°œ ë…¼ë¬¸, {r['elapsed']:.2f}ì´ˆ")
        else:
            print(f"  {status_icon} {r['name']}: {r['error']}")
    
    print_separator()
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(run_all_tests())
