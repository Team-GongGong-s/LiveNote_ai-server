# REC Recommend ë™ì‘ ê³¼ì • (OpenAlex)

## ğŸ“š ê°œìš”

ì´ ë¬¸ì„œëŠ” **OpenAlex ë…¼ë¬¸ ì¶”ì²œ ì‹œìŠ¤í…œ**ì˜ ì „ì²´ ë™ì‘ ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

**í•µì‹¬ íŠ¹ì§•:**
- LLM ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (TOKEN_MIN=2, TOKEN_MAX=3ê°œ í† í°)
- OpenAlex APIë¥¼ í†µí•œ í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰
- ë³‘ë ¬ LLM ê²€ì¦ (Semaphore ë™ì‹œì„± ì œì–´, ìµœëŒ€ 20ê°œ)
- Heuristic ìŠ¤ì½”ì–´ë§ (ë¹ ë¥¸ í‰ê°€)
- NO_SCORING ëª¨ë“œ ì§€ì›
- JSON íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€ (MAX_TOKENS_SCORE=200, reason 50ì ì œí•œ)

---

## ğŸ”„ ì „ì²´ íë¦„ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OpenAlex ë…¼ë¬¸ ì¶”ì²œ ì‹œìŠ¤í…œ                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  1. ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (LLM)                â”‚
        â”‚     - ì„¹ì…˜ ìš”ì•½ ë¶„ì„                    â”‚
        â”‚     - ì´ì „ ì„¹ì…˜ ì»¨í…ìŠ¤íŠ¸                â”‚
        â”‚     - RAG ì»¨í…ìŠ¤íŠ¸                      â”‚
        â”‚     â†’ TOKEN_MIN~TOKEN_MAX í† í° ìƒì„±    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  2. OpenAlex API í˜¸ì¶œ                   â”‚
        â”‚     - tokens: ["term1", "term2", ...]  â”‚
        â”‚     - í•„í„°: year_from, language, type  â”‚
        â”‚     - ì •ë ¬: relevance/cited/hybrid     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  3. ë…¼ë¬¸ íŒŒì‹± + í•„í„°ë§                  â”‚
        â”‚     - ì´ˆë¡ ì—­ìƒ‰ì¸ â†’ í…ìŠ¤íŠ¸ ë³€í™˜        â”‚
        â”‚     - ì´ˆë¡ ì—†ìŒ + ì¸ìš© 100 ë¯¸ë§Œ ì œì™¸   â”‚
        â”‚     - exclude_ids í•„í„°ë§                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  4. ì¤‘ë³µ ì œê±° + ì¬ë­í‚¹                  â”‚
        â”‚     - deduplicate_papers()             â”‚
        â”‚     - rerank_papers()                  â”‚
        â”‚     â†’ ìƒìœ„ CARD_LIMITê°œ ì„ íƒ           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  5. ì¡°ê±´ë¶€ ê²€ì¦                         â”‚
        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
        â”‚     â”‚ verify=Trueâ”‚  verify=False  â”‚    â”‚
        â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
        â”‚     â”‚ LLM ë³‘ë ¬   â”‚  Heuristic     â”‚    â”‚
        â”‚     â”‚ ê²€ì¦       â”‚  ìŠ¤ì½”ì–´ë§      â”‚    â”‚
        â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  6. ì ìˆ˜ í•„í„°ë§ + ì •ë ¬                  â”‚
        â”‚     - min_score ì´ìƒë§Œ ì„ íƒ             â”‚
        â”‚     - ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬                â”‚
        â”‚     â†’ top_kê°œ ë°˜í™˜                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ ë‹¨ê³„ë³„ ìƒì„¸ ì„¤ëª…

### **1ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (LLM)**

**ëª©ì :** ì„¹ì…˜ ìš”ì•½ â†’ í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰ì— ì í•©í•œ TOKEN ìƒì„±

**ì…ë ¥:**
```python
request_data = {
    "section_summary": str,          # í˜„ì¬ ì„¹ì…˜ ìš”ì•½
    "previous_summaries": List[...], # ì´ì „ ì„¹ì…˜ ìš”ì•½ë“¤
    "rag_context": List[...]         # RAG ë²¡í„° DB ê²€ìƒ‰ ê²°ê³¼
}
```

**ì²˜ë¦¬ ê³¼ì •:**
1. **ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„**
   - ì„¹ì…˜ ìš”ì•½: í˜„ì¬ ê°•ì˜ ë‚´ìš©
   - ì´ì „ ì„¹ì…˜: ê°•ì˜ íë¦„ íŒŒì•…
   - RAG ì»¨í…ìŠ¤íŠ¸: ê´€ë ¨ ìë£Œ (ìƒìœ„ 3ê°œ)

2. **LLM í”„ë¡¬í”„íŠ¸ ìƒì„±**
   ```
   QUERY_GENERATION_PROMPT:
   - Extract core concepts and technical terms
   - Use precise academic terminology
   - Expand abbreviations where needed
   - Include field-specific keywords
   - Keep it concise (TOKEN_MIN-TOKEN_MAX tokens max)
   ```

3. **OpenAI API í˜¸ì¶œ**
   - Model: `gpt-4o` (í˜„ì¬ ì„¤ì •)
   - Temperature: `0.2` (ì¼ê´€ì„± ìš°ì„ , 0.3â†’0.2)
   - Max Tokens: `150`

**ì¶œë ¥:**
```json
{
  "tokens": ["neural network", "backpropagation", "gradient descent"],
  "year_from": 1930
}
```

**íŠ¹ì§•:**
- **TOKEN_MIN=2, TOKEN_MAX=3**: 2~3ê°œì˜ í•µì‹¬ í† í° ìƒì„± (4â†’3 ê°ì†Œ)
- **JSON íŒŒì‹± ì˜¤ë¥˜ ëŒ€ì‘**: ì„¹ì…˜ ìš”ì•½ì—ì„œ ë‹¨ì–´ ì¶”ì¶œ (Fallback)
- **ë…„ë„ í•„í„°**: `year_from`ì€ requestì—ì„œ ë°›ìŒ (ê¸°ë³¸: 1930)

---

### **2ë‹¨ê³„: OpenAlex API í˜¸ì¶œ**

**ëª©ì :** ìƒì„±ëœ TOKENìœ¼ë¡œ í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰

**API ì—”ë“œí¬ì¸íŠ¸:**
```
GET https://api.openalex.org/works
```

**ìš”ì²­ íŒŒë¼ë¯¸í„°:**
```python
params = {
    "search": "neural network backpropagation gradient descent",  # tokens ê²°í•©
    "filter": "from_publication_date:1930-01-01,language:en,is_paratext:false,type:article",
    "sort": "relevance_score:desc",  # ì •ë ¬ ì˜µì…˜
    "per_page": 25  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë…¼ë¬¸ ìˆ˜
}
```

**í•„í„° ì„¤ëª…:**
- `from_publication_date:1930-01-01`: 1930ë…„ ì´í›„ ë…¼ë¬¸ë§Œ (ì„¤ì • ê°€ëŠ¥)
- `language:en`: ì˜ì–´ ë…¼ë¬¸ë§Œ
- `is_paratext:false`: ë³´ì¡° ìë£Œ ì œì™¸ (ì‹¤ì œ ë…¼ë¬¸ë§Œ)
- `type:article`: í•™ìˆ  ë…¼ë¬¸ë§Œ (ë¦¬ë·°, ì±… ì œì™¸)

**ì •ë ¬ ì˜µì…˜ (sort_by):**

| ì˜µì…˜ | ì„¤ëª… | ì‚¬ìš© ì‹œê¸° |
|------|------|-----------|
| `relevance` | í‚¤ì›Œë“œ ì—°ê´€ì„± ìš°ì„  (ê¸°ë³¸ê°’) | ê°•ì˜ ì£¼ì œì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë…¼ë¬¸ í•„ìš” |
| `cited_by_count` | ì¸ìš©ìˆ˜ ìš°ì„  | ì˜í–¥ë ¥ ìˆëŠ” ë…¼ë¬¸ í•„ìš” (Seminal paper) |
| `hybrid` | ì—°ê´€ì„± ìƒìœ„ 60% ì¤‘ ì¸ìš©ìˆ˜ ë†’ì€ ë…¼ë¬¸ | ì—°ê´€ì„± + ì˜í–¥ë ¥ ê· í˜• |

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "results": [
    {
      "id": "https://openalex.org/W2100837269",
      "title": "Learning representations by back-propagating errors",
      "abstract_inverted_index": {"We": [0, 45], "describe": [1], ...},
      "publication_year": 1986,
      "cited_by_count": 25834,
      "doi": "https://doi.org/10.1038/323533a0",
      "authorships": [...],
      "relevance_score": 0.98
    }
  ]
}
```

---

### **3ë‹¨ê³„: ë…¼ë¬¸ íŒŒì‹± + í•„í„°ë§**

**ëª©ì :** OpenAlex ì‘ë‹µ â†’ ë‚´ë¶€ í˜•ì‹ ë³€í™˜ + ì €í’ˆì§ˆ ë…¼ë¬¸ ì œê±°

**íŒŒì‹± ê³¼ì •:**

1. **ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ**
   ```python
   paper_id = work.get("id")
   title = work.get("title")
   year = work.get("publication_year")
   cited_by_count = work.get("cited_by_count", 0)
   doi = work.get("doi")
   url = doi if doi else paper_id
   ```

2. **ì´ˆë¡ ì—­ìƒ‰ì¸ â†’ í…ìŠ¤íŠ¸ ë³€í™˜**
   ```python
   # OpenAlexëŠ” ì´ˆë¡ì„ ì—­ìƒ‰ì¸ìœ¼ë¡œ ì €ì¥
   # {"We": [0, 45], "describe": [1], ...} â†’ "We describe ..."
   abstract_inverted = work.get("abstract_inverted_index")
   abstract = parse_abstract_inverted_index(abstract_inverted)
   ```

3. **ì €ì ì¶”ì¶œ (ìƒìœ„ 5ëª…)**
   ```python
   authors = []
   for authorship in work.get("authorships", [])[:5]:
       name = authorship.get("author", {}).get("display_name")
       if name:
           authors.append(name)
   ```

**í•„í„°ë§ ê·œì¹™:**

| ì¡°ê±´ | ì²˜ë¦¬ |
|------|------|
| ì´ˆë¡ ì—†ìŒ + ì¸ìš© 100 ë¯¸ë§Œ | â­ï¸ ì œì™¸ |
| ì´ˆë¡ ì—†ìŒ + ì¸ìš© 100 ì´ìƒ | âœ… ìœ ì§€ (ì˜í–¥ë ¥ ìˆëŠ” ë…¼ë¬¸) |
| exclude_idsì— í¬í•¨ | â­ï¸ ì œì™¸ |
| ì´ˆë¡ 50ì ë¯¸ë§Œ | â­ï¸ ì œì™¸ |

**ì¶œë ¥ í˜•ì‹:**
```python
{
    "id": "https://openalex.org/W2100837269",
    "title": "Learning representations by back-propagating errors",
    "abstract": "We describe a new learning procedure...",
    "year": 1986,
    "cited_by_count": 25834,
    "url": "https://doi.org/10.1038/323533a0",
    "authors": ["Geoffrey E. Hinton", "David E. Rumelhart", ...],
    "no_abstract": False,
    "relevance_score": 0.98
}
```

---

### **4ë‹¨ê³„: ì¤‘ë³µ ì œê±° + ì¬ë­í‚¹**

**ëª©ì :** ìœ ì‚¬ ë…¼ë¬¸ ì œê±° + ì—°ê´€ì„± ì¬í‰ê°€

**ì²˜ë¦¬:**
```python
papers = deduplicate_papers(papers)  # ì œëª© ìœ ì‚¬ë„ ê¸°ë°˜
papers = rerank_papers(papers, query)  # relevance_score ê°€ì¤‘ì¹˜ ì¬ì¡°ì •
papers = papers[:OpenAlexConfig.CARD_LIMIT]  # ìƒìœ„ Nê°œ (ì˜ˆ: 10ê°œ)
```

**CARD_LIMIT:**
- ê²€ì¦ ëŒ€ìƒ ë…¼ë¬¸ ìˆ˜ ì œí•œ (ê¸°ë³¸: 13ê°œ, 10â†’13 ì¦ê°€)
- ê²€ì¦ ì‹œê°„ ë‹¨ì¶• (LLM í˜¸ì¶œ ë¹„ìš© ì ˆê°)

---

### **5ë‹¨ê³„: ì¡°ê±´ë¶€ ê²€ì¦**

**NO_SCORING ëª¨ë“œ:**
```python
if flags.NO_SCORING:
    # ê²€ì¦ ì—†ì´ ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜
    # score=10.0 ê³ ì •, reason="search"
    return papers[:request.top_k]
```

#### **5-1. LLM ë³‘ë ¬ ê²€ì¦ (verify=True)**

**ëª©ì :** GPT-4oë¡œ ë…¼ë¬¸-ê°•ì˜ ì—°ê´€ì„± ì •í™•íˆ í‰ê°€

**ì²˜ë¦¬ íë¦„:**
1. **Semaphore ë™ì‹œì„± ì œì–´**
   ```python
   semaphore = asyncio.Semaphore(VERIFY_CONCURRENCY)  # 20ê°œ ë™ì‹œ ì‹¤í–‰ (5â†’20)
   
   async def verify_with_limit(paper):
       async with semaphore:
           return await _verify_single_paper(paper, request, query)
   
   results = await asyncio.gather(*[verify_with_limit(p) for p in papers])
   ```

2. **LLM í”„ë¡¬í”„íŠ¸**
   ```
   SCORE_PAPER_PROMPT:
   - í˜„ì¬ ì„¹ì…˜ ìš”ì•½: {section_summary}
   - í‚¤ì›Œë“œ: {keywords}
   - ë…¼ë¬¸ ì œëª©: {title}
   - ë…¼ë¬¸ ì´ˆë¡: {abstract}
   - ì¶œíŒ ì—°ë„: {year}
   - ì¸ìš© íšŸìˆ˜: {cited_by_count}
   
   ì ìˆ˜ ê¸°ì¤€ (ì—„ê²©):
   - 10ì : Seminal paper (ê°œë…ì„ ì²˜ìŒ ì œì‹œ)
   - 9ì : ê°•ì˜ í•µì‹¬ ê°œë… ì§ì ‘ ë‹¤ë£¸
   - 7-8ì : í•µì‹¬ ê°œë… ë¶€ë¶„ì /ê°„ì ‘ì 
   - 4-6ì : ê´€ë ¨ ë°°ê²½ì§€ì‹ (ì£¼ì œ ì•½ê°„ ë²—ì–´ë‚¨)
   - 1-3ì : í‚¤ì›Œë“œë§Œ ê²¹ì¹¨
   ```

3. **OpenAI API í˜¸ì¶œ**
   - Model: `gpt-4o`
   - Temperature: `0.2`
   - Max Tokens: `200` (120â†’200, reason ì˜ë¦¼ ë°©ì§€)

**ì¶œë ¥:**
```json
{
  "score": 9.0,
  "reason": "Backpropagation ì•Œê³ ë¦¬ì¦˜ì„ ì²˜ìŒ ì œì‹œí•œ ë…¼ë¬¸ìœ¼ë¡œ, ê°•ì˜ í•µì‹¬ ê°œë…ì„ ì§ì ‘ ë‹¤ë£¸"
}
```

**ì—ëŸ¬ ì²˜ë¦¬:**
- JSON íŒŒì‹± ì‹¤íŒ¨ â†’ Fallback: ì ìˆ˜ë§Œ ì¶”ì¶œ ì‹œë„ (regex)
- reason ì˜ë¦¼ ê°ì§€ â†’ MAX_TOKENS_SCORE ì¦ê°€ ê¶Œì¥
- API ì˜¤ë¥˜ â†’ `score=5.0`, `reason="ê²€ì¦ ì‹¤íŒ¨ (API ì˜¤ë¥˜)"`

#### **5-2. Heuristic ìŠ¤ì½”ì–´ë§ (verify=False)**

**ëª©ì :** LLM ì—†ì´ ë¹ ë¥¸ í‰ê°€ (ë¹„ìš© ì ˆê°, ì†ë„ í–¥ìƒ)

**ì ìˆ˜ ê³„ì‚°:**
```python
score = 5.0  # ê¸°ë³¸ ì ìˆ˜

# í‚¤ì›Œë“œ ë§¤ì¹­
for token in query["tokens"]:
    if token.lower() in title.lower():
        score += 0.5  # ì œëª© ë§¤ì¹­
    if token.lower() in abstract.lower():
        score += 0.2  # ì´ˆë¡ ë§¤ì¹­

# relevance_score ê°€ì¤‘ì¹˜ (ìµœëŒ€ +2ì )
score += min(paper["relevance_score"] / 10, 2.0)

# 10ì  ì´ˆê³¼ ë°©ì§€
score = min(score, 10.0)
```

**íŠ¹ì§•:**
- ì œëª© í‚¤ì›Œë“œ ë§¤ì¹­: +0.5ì /í† í°
- ì´ˆë¡ í‚¤ì›Œë“œ ë§¤ì¹­: +0.2ì /í† í°
- OpenAlex relevance_score í™œìš©
- ê²€ì¦ ì‹œê°„: LLMì˜ 1/10 ì´í•˜

---

### **6ë‹¨ê³„: ì ìˆ˜ í•„í„°ë§ + ì •ë ¬**

**ëª©ì :** ê³ í’ˆì§ˆ ë…¼ë¬¸ë§Œ ì„ íƒ + ìµœì¢… ë°˜í™˜

**ì²˜ë¦¬:**
```python
# min_score ì´ìƒë§Œ ì„ íƒ
filtered_results = [r for r in results if r.score >= request.min_score]

# ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
filtered_results.sort(key=lambda x: x.score, reverse=True)

# top_kê°œ ë°˜í™˜
final_results = filtered_results[:request.top_k]
```

**ë¡œê·¸ ì˜ˆì‹œ:**
```
âœ… ë…¼ë¬¸ ì¶”ì²œ ì™„ë£Œ: 3ê°œ (ìµœê³  ì ìˆ˜: 9.0)
âš ï¸  min_score 4.0 ì´ìƒì¸ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤
```

---

## âš™ï¸ ìœ íš¨í•œ ì„¤ì • ê°€ì´ë“œ

### **1. server/config.py (ì„œë²„ ì„¤ì •)**

```python
class OpenAlexSettings(BaseModel):
    top_k: int = Field(default=3, ge=1, le=10)
    verify: bool = Field(default=True)  # LLM ê²€ì¦ ON/OFF
    year_from: int = Field(default=1930)  # ë…¼ë¬¸ ì¶œíŒ ë…„ë„ í•„í„°
    min_score: float = Field(default=0.0, ge=0.0, le=10.0)  # ìµœì†Œ ì ìˆ˜
    sort_by: str = Field(default="relevance")  # relevance/cited_by_count/hybrid
```

**ì„¤ì • ê¶Œì¥ ê°’:**

| ì„¤ì • | ê¶Œì¥ ê°’ | ì„¤ëª… |
|------|---------|------|
| `top_k` | `3` | ë°˜í™˜í•  ë…¼ë¬¸ ìˆ˜ (1~10) |
| `verify` | `True` | LLM ê²€ì¦ í™œì„±í™” (ì •í™•ë„ ìš°ì„ ) |
| `year_from` | `2015` | ìµœê·¼ ë…¼ë¬¸ ìš°ì„  (íŠ¸ë Œë“œ íŒŒì•…) |
| `min_score` | `7.0` | ê³ í’ˆì§ˆ ë…¼ë¬¸ë§Œ í•„í„°ë§ |
| `sort_by` | `relevance` | ê°•ì˜ ì£¼ì œì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë…¼ë¬¸ |

**âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ ë¬¸ì œ:**
- `year_from=1930` + `min_score=0.0`: ë„ˆë¬´ ê´€ëŒ€í•¨ (í’ˆì§ˆ ë‚®ìŒ)
- `year_from=1930` + TOKEN ë³‘ë ¬ ê²€ìƒ‰ ì‹¤íŒ¨: ëª¨ë“  TOKENì´ ë§¤ì¹­ ì•ˆ ë¨
- **í•´ê²°ì±…**: `year_from=2015`, `min_score=7.0`, `verify=True`

### **2. cap1_openalex_module/openalexkit/config/openalex_config.py**

```python
class OpenAlexConfig:
    # LLM ì„¤ì •
    LLM_MODEL: str = "gpt-4o"
    LLM_TEMPERATURE: float = 0.2  # 0.3â†’0.2
    
    # TOKEN ìƒì„± ë²”ìœ„
    TOKEN_MIN: int = 2  # ìµœì†Œ í† í° ìˆ˜
    TOKEN_MAX: int = 3  # ìµœëŒ€ í† í° ìˆ˜ (4â†’3)
    
    # ê²€ìƒ‰ ì„¤ì •
    PER_PAGE: int = 40  # API í˜ì´ì§€ë‹¹ ë…¼ë¬¸ ìˆ˜ (25â†’40)
    CARD_LIMIT: int = 13  # ê²€ì¦ ëŒ€ìƒ ë…¼ë¬¸ ìˆ˜ (10â†’13)
    
    # ê²€ì¦ ì„¤ì •
    VERIFY_CONCURRENCY: int = 20  # ë³‘ë ¬ ê²€ì¦ ë™ì‹œì„± (5â†’20)
    
    # í•„í„°ë§ ì„¤ì •
    ABSTRACT_MAX_LENGTH: int = 400  # LLM ì „ë‹¬ ì´ˆë¡ ê¸¸ì´
    DEFAULT_YEAR_FROM: int = 1930  # ê¸°ë³¸ ë…„ë„ í•„í„°
    
    # LLM í† í° ì„¤ì •
    MAX_TOKENS_QUERY: int = 150  # ì¿¼ë¦¬ ìƒì„±
    MAX_TOKENS_SCORE: int = 200  # ë…¼ë¬¸ ê²€ì¦ (120â†’200)
```

**ì„¤ì • ì¡°ì • ê°€ì´ë“œ:**

| ì‹œë‚˜ë¦¬ì˜¤ | ì„¤ì • |
|---------|------|
| ê³ í’ˆì§ˆ ë…¼ë¬¸ë§Œ í•„ìš” | `year_from=2015`, `min_score=7.0`, `verify=True` |
| ë¹ ë¥¸ ì‘ë‹µ í•„ìš” | `verify=False` (Heuristic), `CARD_LIMIT=5` |
| ìµœì‹  íŠ¸ë Œë“œ íŒŒì•… | `year_from=2020`, `sort_by=cited_by_count` |
| Seminal paper ì°¾ê¸° | `year_from=1930`, `sort_by=cited_by_count`, `min_score=9.0` |
| ë¹„ìš© ì ˆê° | `verify=False`, `CARD_LIMIT=5`, `PER_PAGE=10` |

### **3. cap1_openalex_module/openalexkit/config/flags.py**

```python
NO_SCORING = False  # True: ê²€ì¦ ìŠ¤í‚µ, False: ê²€ì¦ ì‹¤í–‰
TOKEN_MIN = 2       # LLM ìƒì„± ìµœì†Œ í† í° ìˆ˜
TOKEN_MAX = 3       # LLM ìƒì„± ìµœëŒ€ í† í° ìˆ˜ (4â†’3)
```

---

## ğŸ” ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ FAQ

### Q1: "ìê¾¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ë‹¤ëŠ”ë°, ì™œ ê·¸ëŸ´ê¹Œ?"

**ê°€ëŠ¥í•œ ì›ì¸:**

1. **TOKEN ìƒì„± ì‹¤íŒ¨**
   ```
   ğŸ“ ìƒì„±ëœ ì¿¼ë¦¬: tokens=[], year_from=1930
   âš ï¸  ê²€ìƒ‰ í† í°ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤
   ```
   - LLMì´ ì„¹ì…˜ ìš”ì•½ì—ì„œ í•™ìˆ  ìš©ì–´ ì¶”ì¶œ ì‹¤íŒ¨
   - **í•´ê²°**: ì„¹ì…˜ ìš”ì•½ í’ˆì§ˆ í™•ì¸, LLM í”„ë¡¬í”„íŠ¸ ê°œì„ 

2. **TOKENì´ ë„ˆë¬´ êµ¬ì²´ì **
   ```
   tokens=["neural network backpropagation gradient descent momentum optimization"]
   âš ï¸  ê²€ìƒ‰ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤
   ```
   - ëª¨ë“  TOKENì´ ë™ì‹œì— í¬í•¨ëœ ë…¼ë¬¸ì´ ì—†ìŒ
   - **í•´ê²°**: `TOKEN_MIN=2`, `TOKEN_MAX=3` (ë²”ìœ„ ì¢íˆê¸°)

3. **year_from í•„í„°ê°€ ë„ˆë¬´ ìµœê·¼**
   ```
   year_from=2023
   âš ï¸  ê²€ìƒ‰ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤
   ```
   - 2023ë…„ ì´í›„ ë…¼ë¬¸ì´ OpenAlexì— ì•„ì§ ë“±ë¡ ì•ˆ ë¨
   - **í•´ê²°**: `year_from=2015` (ìµœê·¼ 10ë…„)

4. **min_score ì„ê³„ê°’ì´ ë„ˆë¬´ ë†’ìŒ**
   ```
   ğŸ” ì ìˆ˜ í•„í„°ë§: 5ê°œ â†’ 0ê°œ (min_score: 9.0)
   âš ï¸  min_score 9.0 ì´ìƒì¸ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤
   ```
   - ê²€ì¦ì€ ì™„ë£Œí–ˆìœ¼ë‚˜ ì ìˆ˜ê°€ ë‚®ìŒ
   - **í•´ê²°**: `min_score=7.0` (í˜„ì‹¤ì ì¸ ì„ê³„ê°’)

5. **OpenAlex API íƒ€ì„ì•„ì›ƒ/ì˜¤ë¥˜**
   ```
   âŒ OpenAlex API íƒ€ì„ì•„ì›ƒ
   âŒ OpenAlex API HTTP ì˜¤ë¥˜: 429 (Too Many Requests)
   ```
   - API ì œí•œ ì´ˆê³¼, ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ
   - **í•´ê²°**: ì¬ì‹œë„, API í‚¤ ì„¤ì • (rate limit ì¦ê°€)

### Q2: "ì½”ë“œ ë¬¸ì œëŠ” ì•„ë‹ˆê³  ì§„ì§œ ê²€ìƒ‰ ëœê²Œ ì—†ëŠ”ê±°ì•¼?"

**í™•ì¸ ë°©ë²•:**

1. **ë¡œê·¸ ë¶„ì„**
   ```python
   # service.py ë¡œê·¸ í™•ì¸
   logger.info(f"ğŸ“ ìƒì„±ëœ ì¿¼ë¦¬: tokens={query.get('tokens', [])}, year_from={query.get('year_from')}")
   logger.info(f"ğŸŒ OpenAlex API í˜¸ì¶œ (tokens={len(query.get('tokens', []))}ê°œ)")
   logger.info(f"ğŸ“š ê²€ìƒ‰ëœ ë…¼ë¬¸: {len(papers)}ê°œ")
   ```

2. **OpenAlex API ì§ì ‘ í…ŒìŠ¤íŠ¸**
   ```bash
   # ë¸Œë¼ìš°ì €ì—ì„œ í™•ì¸
   https://api.openalex.org/works?search=neural+network+backpropagation&filter=from_publication_date:1930-01-01,language:en,is_paratext:false,type:article&sort=relevance_score:desc&per_page=25
   ```

3. **TOKEN ë³‘ë ¬ ê²€ìƒ‰ í™•ì¸**
   ```python
   # openalex_client.py
   # tokens = ["neural network", "backpropagation", "gradient descent"]
   # search_str = "neural network backpropagation gradient descent"
   # â†’ OpenAlexëŠ” "AND" ê²€ìƒ‰ (ëª¨ë“  TOKEN í¬í•¨ ë…¼ë¬¸ë§Œ)
   ```

**íŒë‹¨ ê¸°ì¤€:**
- `ğŸ“š ê²€ìƒ‰ëœ ë…¼ë¬¸: 0ê°œ` â†’ **OpenAlex API ë¬¸ì œ** (TOKENì´ ë„ˆë¬´ êµ¬ì²´ì )
- `ğŸ“š ê²€ìƒ‰ëœ ë…¼ë¬¸: 25ê°œ` â†’ `âš ï¸ min_score ì´ìƒì¸ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤` â†’ **ê²€ì¦ ë¬¸ì œ** (min_score ë‚®ì¶”ê¸°)

### Q3: "TOKEN_MIN=2, TOKEN_MAX=4 ë³‘ë ¬ ê²€ìƒ‰ì—ì„œ ì¼ì¹˜í•˜ëŠ”ê²Œ ì—†ì–´ì„œ?"

**ì•„ë‹ˆìš”, TOKENì€ ë³‘ë ¬ ê²€ìƒ‰ì´ ì•„ë‹™ë‹ˆë‹¤!**

**ì˜ëª»ëœ ì´í•´:**
```
âŒ tokens = ["neural network", "backpropagation"]
âŒ â†’ "neural network" OR "backpropagation" (OR ê²€ìƒ‰)
```

**ì˜¬ë°”ë¥¸ ë™ì‘:**
```
âœ… tokens = ["neural network", "backpropagation"]
âœ… search_str = "neural network backpropagation"
âœ… â†’ "neural network AND backpropagation" (AND ê²€ìƒ‰)
```

**ì‹¤ì œ ì²˜ë¦¬:**
```python
# openalex_client.py, ë¼ì¸ 47-48
tokens = query.get("tokens", [])
search_str = " ".join(tokens)  # ê³µë°±ìœ¼ë¡œ ê²°í•©
```

**OpenAlex ê²€ìƒ‰ ë™ì‘:**
- `search_str = "neural network backpropagation"`
- OpenAlexëŠ” **ëª¨ë“  ë‹¨ì–´ê°€ í¬í•¨ëœ ë…¼ë¬¸ë§Œ** ë°˜í™˜ (AND ê²€ìƒ‰)
- TOKENì´ ë§ì„ìˆ˜ë¡ ê²€ìƒ‰ ê²°ê³¼ **ê°ì†Œ** (ë” êµ¬ì²´ì )

**í•´ê²° ë°©ë²•:**
- `TOKEN_MIN=2`, `TOKEN_MAX=3`: í† í° ìˆ˜ ì¤„ì´ê¸°
- `sort_by=hybrid`: ì—°ê´€ì„± ë†’ì€ ë…¼ë¬¸ ì¤‘ ì¸ìš©ìˆ˜ ë†’ì€ ê²ƒ ì„ íƒ
- `year_from=2015`: ìµœê·¼ ë…¼ë¬¸ìœ¼ë¡œ ë²”ìœ„ ì¢íˆê¸°

---

## ğŸ“Š ì‹¤ì œ ì˜ˆì‹œ

### **ì˜ˆì‹œ 1: ì„±ê³µ ì¼€ì´ìŠ¤ (ê²€ìƒ‰ ê²°ê³¼ ìˆìŒ)**

**ì…ë ¥:**
```python
request = OpenAlexRequest(
    lecture_id="lecture_1",
    section_id="section_3",
    section_summary="ì´ ì„¹ì…˜ì—ì„œëŠ” Backpropagation ì•Œê³ ë¦¬ì¦˜ì˜ ì›ë¦¬ì™€ gradient descent ìµœì í™” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.",
    previous_summaries=[],
    rag_context=[],
    year_from=2015,
    top_k=3,
    verify_openalex=True,
    min_score=7.0
)
```

**ì²˜ë¦¬:**
```
1. ì¿¼ë¦¬ ìƒì„± (LLM)
   tokens=["backpropagation", "gradient descent", "neural network"]

2. OpenAlex API í˜¸ì¶œ
   search_str="backpropagation gradient descent neural network"
   year_from=2015
   ğŸ“š ê²€ìƒ‰ëœ ë…¼ë¬¸: 18ê°œ

3. íŒŒì‹± + í•„í„°ë§
   ì´ˆë¡ ì—†ìŒ + ì¸ìš© 100 ë¯¸ë§Œ ì œì™¸ â†’ 15ê°œ

4. ì¤‘ë³µ ì œê±° + ì¬ë­í‚¹
   ìƒìœ„ 10ê°œ ì„ íƒ (CARD_LIMIT)

5. LLM ë³‘ë ¬ ê²€ì¦
   âœ¨ ë³‘ë ¬ LLM ê²€ì¦ ì‹œì‘ (ë™ì‹œì„±: 5)
   âœ… ë³‘ë ¬ ê²€ì¦ ì™„ë£Œ: 10ê°œ
   
   ê²°ê³¼ ì˜ˆì‹œ:
   - Paper 1: score=9.0, "Backpropagation ì•Œê³ ë¦¬ì¦˜ì„ ë‹¤ë£¬ í•µì‹¬ ë…¼ë¬¸"
   - Paper 2: score=8.5, "Gradient descent ìµœì í™” ë°©ë²• ìƒì„¸ ì„¤ëª…"
   - Paper 3: score=7.8, "Neural network training ì „ë°˜ ë‹¤ë£¸"

6. ì ìˆ˜ í•„í„°ë§ + ì •ë ¬
   min_score=7.0 ì´ìƒ: 8ê°œ â†’ top_k=3 ë°˜í™˜

âœ… ë…¼ë¬¸ ì¶”ì²œ ì™„ë£Œ: 3ê°œ (ìµœê³  ì ìˆ˜: 9.0)
```

**ì¶œë ¥:**
```json
[
  {
    "lecture_id": "lecture_1",
    "section_id": "section_3",
    "paper_info": {
      "title": "Efficient BackProp",
      "authors": ["Yann LeCun", "LÃ©on Bottou", ...],
      "year": 2012,
      "citations": 15234,
      "url": "https://doi.org/...",
      "abstract": "We present a practical guide to..."
    },
    "reason": "Backpropagation ì•Œê³ ë¦¬ì¦˜ì˜ íš¨ìœ¨ì  êµ¬í˜„ì„ ë‹¤ë£¬ í•µì‹¬ ë…¼ë¬¸",
    "score": 9.0
  },
  ...
]
```

### **ì˜ˆì‹œ 2: ì‹¤íŒ¨ ì¼€ì´ìŠ¤ (ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)**

**ì…ë ¥:**
```python
request = OpenAlexRequest(
    lecture_id="lecture_2",
    section_id="section_5",
    section_summary="ì´ë²ˆ ì„¹ì…˜ì—ì„œëŠ” ìµœì‹  AI ê¸°ìˆ ì˜ ìœ¤ë¦¬ì  ìŸì ì„ ë…¼ì˜í•©ë‹ˆë‹¤.",
    previous_summaries=[],
    rag_context=[],
    year_from=1930,  # âš ï¸ ë„ˆë¬´ ì˜¤ë˜ë¨
    top_k=3,
    verify_openalex=True,
    min_score=0.0
)
```

**ì²˜ë¦¬:**
```
1. ì¿¼ë¦¬ ìƒì„± (LLM)
   tokens=["AI ethics", "ethical issues", "artificial intelligence morality"]
   âš ï¸ TOKENì´ ë„ˆë¬´ ë§ê³  êµ¬ì²´ì  (4ê°œ)

2. OpenAlex API í˜¸ì¶œ
   search_str="AI ethics ethical issues artificial intelligence morality"
   year_from=1930
   âš ï¸ ëª¨ë“  TOKENì´ ë™ì‹œì— í¬í•¨ëœ ë…¼ë¬¸ì´ ì—†ìŒ
   ğŸ“š ê²€ìƒ‰ëœ ë…¼ë¬¸: 0ê°œ

âŒ ë…¼ë¬¸ ì¶”ì²œ ì‹¤íŒ¨: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
```

**í•´ê²°:**
```python
# ì„¤ì • ìˆ˜ì •
request = OpenAlexRequest(
    year_from=2015,  # ìµœê·¼ ë…¼ë¬¸ë§Œ
    min_score=7.0,   # ê³ í’ˆì§ˆ í•„í„°
    top_k=3,
    verify_openalex=True
)

# + prompts.py ìˆ˜ì • (TOKEN ë²”ìœ„ ì¢íˆê¸°)
TOKEN_MIN = 2
TOKEN_MAX = 3  # 4 â†’ 3
```

**ì¬ì‹œë„:**
```
1. ì¿¼ë¦¬ ìƒì„± (LLM)
   tokens=["AI ethics", "artificial intelligence"]
   âœ… TOKEN ìˆ˜ ê°ì†Œ (4 â†’ 2)

2. OpenAlex API í˜¸ì¶œ
   search_str="AI ethics artificial intelligence"
   year_from=2015
   ğŸ“š ê²€ìƒ‰ëœ ë…¼ë¬¸: 42ê°œ

3-6. (ì¤‘ëµ)

âœ… ë…¼ë¬¸ ì¶”ì²œ ì™„ë£Œ: 3ê°œ (ìµœê³  ì ìˆ˜: 8.5)
```

---

## ğŸš€ ìµœì í™” íŒ

### **1. ë¹ ë¥¸ ì‘ë‹µì´ í•„ìš”í•  ë•Œ**
```python
# server/config.py
class OpenAlexSettings(BaseModel):
    verify: bool = Field(default=False)  # Heuristic ìŠ¤ì½”ì–´ë§
    top_k: int = Field(default=3)

# cap1_openalex_module/openalexkit/config/openalex_config.py
CARD_LIMIT = 5  # ê²€ì¦ ëŒ€ìƒ ì¤„ì´ê¸°
PER_PAGE = 10   # API í˜¸ì¶œ ê²°ê³¼ ì¤„ì´ê¸°
```

### **2. ê³ í’ˆì§ˆ ë…¼ë¬¸ë§Œ í•„ìš”í•  ë•Œ**
```python
# server/config.py
class OpenAlexSettings(BaseModel):
    verify: bool = Field(default=True)  # LLM ê²€ì¦
    min_score: float = Field(default=7.0)  # ë†’ì€ ì„ê³„ê°’
    year_from: int = Field(default=2015)  # ìµœê·¼ ë…¼ë¬¸
```

### **3. ë¹„ìš© ì ˆê°ì´ í•„ìš”í•  ë•Œ**
```python
# NO_SCORING ëª¨ë“œ í™œì„±í™”
# cap1_openalex_module/openalexkit/config/flags.py
NO_SCORING = True  # ê²€ì¦ ìŠ¤í‚µ

# ë˜ëŠ” Heuristic ìŠ¤ì½”ì–´ë§
verify: bool = Field(default=False)
CARD_LIMIT = 5
```

### **4. ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ í•´ê²°**
```python
# 1. TOKEN ë²”ìœ„ ì¤„ì´ê¸°
TOKEN_MIN = 2
TOKEN_MAX = 3  # 4 â†’ 3

# 2. year_from ì¡°ì •
year_from = 2015  # 1930 â†’ 2015

# 3. min_score ë‚®ì¶”ê¸°
min_score = 7.0  # 9.0 â†’ 7.0

# 4. sort_by ë³€ê²½
sort_by = "hybrid"  # relevance â†’ hybrid (ì—°ê´€ì„± + ì¸ìš©ìˆ˜)
```

---

## ğŸ“ ìš”ì•½

**OpenAlex ë…¼ë¬¸ ì¶”ì²œ ì‹œìŠ¤í…œ**ì€ 6ë‹¨ê³„ë¡œ ë™ì‘í•©ë‹ˆë‹¤:

1. **ì¿¼ë¦¬ ìƒì„±**: LLMì´ ì„¹ì…˜ ìš”ì•½ â†’ 2-4ê°œ í•™ìˆ  TOKEN ìƒì„±
2. **API í˜¸ì¶œ**: OpenAlex APIë¡œ ë…¼ë¬¸ ê²€ìƒ‰ (ë…„ë„, ì–¸ì–´, íƒ€ì… í•„í„°)
3. **íŒŒì‹±**: ì´ˆë¡ ì—­ìƒ‰ì¸ ë³€í™˜, ì €í’ˆì§ˆ ë…¼ë¬¸ ì œê±°
4. **ì¬ë­í‚¹**: ì¤‘ë³µ ì œê±° + ì—°ê´€ì„± ì¬í‰ê°€ â†’ ìƒìœ„ 10ê°œ ì„ íƒ
5. **ê²€ì¦**: LLM ë³‘ë ¬ ê²€ì¦ (verify=True) ë˜ëŠ” Heuristic ìŠ¤ì½”ì–´ë§ (verify=False)
6. **ë°˜í™˜**: min_score ì´ìƒ + ì ìˆ˜ ì •ë ¬ â†’ top_kê°œ ë°˜í™˜

**í•µì‹¬ ì„¤ì •:**
- `year_from=2015`: ìµœê·¼ ë…¼ë¬¸ ìš°ì„ 
- `min_score=7.0`: ê³ í’ˆì§ˆ í•„í„°
- `verify=True`: LLM ê²€ì¦ (ì •í™•ë„ ìš°ì„ )
- `TOKEN_MIN=2, TOKEN_MAX=3`: í† í° ìˆ˜ ì ì ˆíˆ ì œí•œ

**ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ í•´ê²°:**
- TOKEN ë²”ìœ„ ì¤„ì´ê¸° (TOKEN_MAX=3)
- year_from ì¡°ì • (2015)
- min_score ë‚®ì¶”ê¸° (7.0)
- sort_by ë³€ê²½ (hybrid)
- ë¡œê·¸ ë¶„ì„ (ì–´ëŠ ë‹¨ê³„ì—ì„œ ì‹¤íŒ¨?)

---

**ì‘ì„±ì¼:** 2025ë…„ 11ì›” 14ì¼  
**ë²„ì „:** 1.1  
**ì—…ë°ì´íŠ¸:** TOKEN_MAX: 4â†’3, MAX_TOKENS_SCORE: 120â†’200, VERIFY_CONCURRENCY: 5â†’20  
**ê´€ë ¨ íŒŒì¼:**
- `cap1_openalex_module/openalexkit/service.py` (ë©”ì¸ ë¡œì§)
- `cap1_openalex_module/openalexkit/llm/openai_client.py` (LLM í´ë¼ì´ì–¸íŠ¸)
- `cap1_openalex_module/openalexkit/api/openalex_client.py` (API í´ë¼ì´ì–¸íŠ¸)
- `cap1_openalex_module/openalexkit/config/prompts.py` (í”„ë¡¬í”„íŠ¸)
- `server/config.py` (ì„œë²„ ì„¤ì •)
