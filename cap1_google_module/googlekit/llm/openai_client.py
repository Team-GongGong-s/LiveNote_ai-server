"""
Google ê²€ìƒ‰ì„ ìœ„í•œ OpenAI LLM í´ë¼ì´ì–¸íŠ¸
"""
import asyncio
import json
import logging
from typing import List, Dict, Any

from openai import AsyncOpenAI

from ..config.google_config import GoogleConfig
from ..config import prompts

logger = logging.getLogger(__name__)


class GoogleLLMClient:
    """Google ê²€ìƒ‰ì„ ìœ„í•œ LLM í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, api_key: str = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©)
        """
        api_key = api_key or GoogleConfig.OPENAI_API_KEY
        if not api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = GoogleConfig.LLM_MODEL
        self.temperature = GoogleConfig.LLM_TEMPERATURE
    
    async def generate_keywords(
        self,
        lecture_summary: str,
        language: str,
        previous_summaries: List[Dict] = None,
        rag_context: List[Dict] = None
    ) -> List[str]:
        """
        ê°•ì˜ ìš”ì•½ â†’ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
        
        Args:
            lecture_summary: ê°•ì˜ ìš”ì•½
            language: í‚¤ì›Œë“œ ìƒì„± ì–¸ì–´ (search_lang)
            previous_summaries: ì´ì „ ì„¹ì…˜ ìš”ì•½ (ì„ íƒ)
            rag_context: RAG ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)
            
        Returns:
            ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = ""
        if previous_summaries or rag_context:
            prev_text = ""
            if previous_summaries:
                prev_text = "\n".join([
                    f"Section {s['section_id']}: {s['summary']}"
                    for s in previous_summaries[:3]  # ìµœê·¼ 3ê°œë§Œ
                ])
            
            rag_text = ""
            if rag_context:
                rag_text = "\n".join([
                    chunk['text'][:200]
                    for chunk in rag_context[:3]  # ìµœëŒ€ 3ê°œ
                ])
            
            context = prompts.KEYWORD_CONTEXT_TEMPLATE.format(
                previous_summaries=prev_text or "None",
                rag_context=rag_text or "None"
            )
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = prompts.KEYWORD_GENERATION_PROMPT.format(
            language=language,
            lecture_summary=lecture_summary,
            context=context
        )
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=self.temperature,
                max_tokens=GoogleConfig.MAX_TOKENS_QUERY,
            )
            
            content = response.choices[0].message.content.strip()
            
            # í‚¤ì›Œë“œ íŒŒì‹± (ì¤„ë°”ê¿ˆ ê¸°ì¤€)
            keywords = [
                line.strip()
                for line in content.split('\n')
                if line.strip() and not line.strip().startswith('#')
            ]
            
            logger.info(f"ğŸ¤– LLM í‚¤ì›Œë“œ ìƒì„±: {keywords}")
            
            return keywords[:GoogleConfig.FANOUT]  # ìµœëŒ€ FANOUT ê°œìˆ˜ë§Œ ë°˜í™˜
        
        except Exception as e:
            logger.error(f"âŒ LLM í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°•ì˜ ìš”ì•½ì˜ ì£¼ìš” ë‹¨ì–´ ì¶”ì¶œ
            fallback = lecture_summary.split()[:3]
            logger.warning(f"âš ï¸  í´ë°± í‚¤ì›Œë“œ ì‚¬ìš©: {fallback}")
            return fallback
    
    async def score_result(
        self,
        lecture_summary: str,
        title: str,
        snippet: str,
        language: str
    ) -> Dict[str, Any]:
        """
        ê²€ìƒ‰ ê²°ê³¼ LLM ê²€ì¦
        
        Args:
            lecture_summary: ê°•ì˜ ìš”ì•½
            title: ê²€ìƒ‰ ê²°ê³¼ ì œëª©
            snippet: ê²€ìƒ‰ ê²°ê³¼ ìŠ¤ë‹ˆí«
            language: ì‘ë‹µ ì–¸ì–´
            
        Returns:
            {"score": 8.5, "reason": "..."}
        """
        prompt = prompts.SCORING_PROMPT.format(
            lecture_summary=lecture_summary,
            title=title,
            snippet=snippet,
            language=language
        )
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=self.temperature,
                max_tokens=GoogleConfig.MAX_TOKENS_SCORE,
                response_format={"type": "json_object"}
            )
            
            content = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                result = json.loads(content)
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ë‚´ìš©: {content[:200]}")
                # ê°„ë‹¨í•œ ì •ê·œì‹ìœ¼ë¡œ scoreì™€ reason ì¶”ì¶œ ì‹œë„
                import re
                score_match = re.search(r'"score"\s*:\s*([0-9.]+)', content)
                reason_match = re.search(r'"reason"\s*:\s*"([^"]*)"', content)
                
                if score_match and reason_match:
                    return {
                        "score": float(score_match.group(1)),
                        "reason": reason_match.group(1)
                    }
                raise e
            
            return {
                "score": float(result.get("score", 0.0)),
                "reason": result.get("reason", "")
            }
        
        except Exception as e:
            logger.error(f"âŒ LLM ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {"score": 0.0, "reason": "ê²€ì¦ ì‹¤íŒ¨"}
